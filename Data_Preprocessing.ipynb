{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "DATA AUGMENTATION"
      ],
      "metadata": {
        "id": "2e0d7H8jNrVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SmAIiCkUMD6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will try to use the give HR images in the the training set to augment more images and then downgrade them to Bicubical to create corresponding LR images."
      ],
      "metadata": {
        "id": "ax7Zc2-vMFh3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVVHCL9xGAwI",
        "outputId": "d7ca8453-f0af-4468-e2db-5b19c3ba498a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 80/80 [01:49<00:00,  1.37s/it]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from PIL import Image, ImageFilter\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms.functional as F\n",
        "from tqdm import tqdm\n",
        "%cd /content/drive/MyDrive/Colab Notebooks\n",
        "\n",
        "HR_DIR = 'scaling_4x/train/HR'\n",
        "AUG_HR_DIR = 'data/HR'\n",
        "AUG_LR_DIR = 'data/LR'\n",
        "os.makedirs(AUG_HR_DIR, exist_ok=True)\n",
        "os.makedirs(AUG_LR_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "def augment_hr_image(hr_img):\n",
        "\n",
        "    hr_crop = T.RandomCrop(256)(hr_img)\n",
        "\n",
        "    #  flip\n",
        "    if random.random() > 0.5:\n",
        "        hr_crop = F.hflip(hr_crop)\n",
        "\n",
        "    # rotation\n",
        "    if random.random() > 0.7:\n",
        "        hr_crop = F.rotate(hr_crop, angle=random.choice([90, 180, 270]))\n",
        "\n",
        "    # jitter\n",
        "    color_aug = T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2)\n",
        "    hr_crop = color_aug(hr_crop)\n",
        "\n",
        "    return hr_crop\n",
        "\n",
        "def degrade_hr_to_lr(hr_img):\n",
        "\n",
        "    lr_img = hr_img.resize((64, 64), Image.BICUBIC)\n",
        "\n",
        "\n",
        "    if random.random() > 0.7:\n",
        "        lr_img = lr_img.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.2, 0.5)))\n",
        "\n",
        "    return lr_img\n",
        "\n",
        "n_aug_per_image = 11\n",
        "image_files = [f for f in os.listdir(HR_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "for img_file in tqdm(image_files):\n",
        "    hr_path = os.path.join(HR_DIR, img_file)\n",
        "    hr_img = Image.open(hr_path).convert('RGB')\n",
        "\n",
        "    base_name = os.path.splitext(img_file)[0]\n",
        "\n",
        "    for i in range(n_aug_per_image):\n",
        "        aug_hr = augment_hr_image(hr_img)\n",
        "        aug_lr = degrade_hr_to_lr(aug_hr)\n",
        "\n",
        "        hr_save_path = os.path.join(AUG_HR_DIR, f\"{base_name}_aug{i}.png\")\n",
        "        lr_save_path = os.path.join(AUG_LR_DIR, f\"{base_name}_aug{i}.png\")\n",
        "\n",
        "        aug_hr.save(hr_save_path)\n",
        "        aug_lr.save(lr_save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "HR_DIR = 'data/HR'\n",
        "LR_DIR = 'data/LR'\n",
        "VAL_HR_DIR = 'dataset/val/HR'\n",
        "VAL_LR_DIR = 'dataset/val/LR'\n",
        "TRAIN_HR_DIR = 'dataset/train/HR'\n",
        "TRAIN_LR_DIR = 'dataset/train/LR'\n",
        "\n",
        "\n",
        "os.makedirs(VAL_HR_DIR, exist_ok=True)\n",
        "os.makedirs(VAL_LR_DIR, exist_ok=True)\n",
        "os.makedirs(TRAIN_HR_DIR, exist_ok=True)\n",
        "os.makedirs(TRAIN_LR_DIR, exist_ok=True)\n",
        "\n",
        "grouped = defaultdict(list)\n",
        "for fname in os.listdir(HR_DIR):\n",
        "    if fname.endswith(\".png\"):\n",
        "        base = fname.split('_aug')[0]\n",
        "        grouped[base].append(fname)\n",
        "\n",
        "validation_set = []\n",
        "remaining_set = []\n",
        "\n",
        "for group_imgs in grouped.values():\n",
        "    if len(group_imgs) == 0:\n",
        "        continue\n",
        "    val_img = random.choice(group_imgs)\n",
        "    validation_set.append(val_img)\n",
        "    remaining_imgs = [img for img in group_imgs if img != val_img]\n",
        "    remaining_set.extend(remaining_imgs)\n",
        "\n",
        "\n",
        "needed = 100 - len(validation_set)\n",
        "if needed > 0:\n",
        "    extra_val_imgs = random.sample(remaining_set, needed)\n",
        "    validation_set.extend(extra_val_imgs)\n",
        "    remaining_set = [img for img in remaining_set if img not in extra_val_imgs]\n",
        "\n",
        "\n",
        "def move_set(file_list, hr_src, lr_src, hr_dst, lr_dst):\n",
        "    for fname in file_list:\n",
        "        shutil.copy(os.path.join(hr_src, fname), os.path.join(hr_dst, fname))\n",
        "        shutil.copy(os.path.join(lr_src, fname), os.path.join(lr_dst, fname))\n",
        "\n",
        "move_set(validation_set, HR_DIR, LR_DIR, VAL_HR_DIR, VAL_LR_DIR)\n",
        "move_set(remaining_set, HR_DIR, LR_DIR, TRAIN_HR_DIR, TRAIN_LR_DIR)\n",
        "\n",
        "print(f\"Validation set: {len(validation_set)} images\")\n",
        "print(f\"Training set: {len(remaining_set)} images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9z97nhVPasI",
        "outputId": "365362b2-b871-4581-f8db-471681fcaf3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n",
            "Validation set: 100 images\n",
            "Training set: 780 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HR_DIR = '/dataset/train/HR'\n",
        "LR_DIR = '/dataset/train/LR'\n"
      ],
      "metadata": {
        "id": "GQB1XY7VPdYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "HR_DIR = '/content/drive/MyDrive/Colab Notebooks/dataset/train/HR'\n",
        "LR_DIR = '/content/drive/MyDrive/Colab Notebooks/dataset/train/LR'\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab Notebooks\n",
        "\n",
        "file_list = [f for f in os.listdir(HR_DIR) if f.endswith('.png')]\n",
        "random.shuffle(file_list)\n",
        "\n",
        "for fname in file_list[:5]:\n",
        "    hr_path = os.path.join(HR_DIR, fname)\n",
        "    lr_path = os.path.join(LR_DIR, fname)\n",
        "    print(f\"HR: {hr_path}\\nLR: {lr_path}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8eyoqDHSPw1",
        "outputId": "94f781ea-181f-4329-f084-7d485eb258ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n",
            "HR: /content/drive/MyDrive/Colab Notebooks/dataset/train/HR/227092_aug8.png\n",
            "LR: /content/drive/MyDrive/Colab Notebooks/dataset/train/LR/227092_aug8.png\n",
            "\n",
            "HR: /content/drive/MyDrive/Colab Notebooks/dataset/train/HR/119082_aug4.png\n",
            "LR: /content/drive/MyDrive/Colab Notebooks/dataset/train/LR/119082_aug4.png\n",
            "\n",
            "HR: /content/drive/MyDrive/Colab Notebooks/dataset/train/HR/299086_aug9.png\n",
            "LR: /content/drive/MyDrive/Colab Notebooks/dataset/train/LR/299086_aug9.png\n",
            "\n",
            "HR: /content/drive/MyDrive/Colab Notebooks/dataset/train/HR/123074_aug7.png\n",
            "LR: /content/drive/MyDrive/Colab Notebooks/dataset/train/LR/123074_aug7.png\n",
            "\n",
            "HR: /content/drive/MyDrive/Colab Notebooks/dataset/train/HR/182053_aug6.png\n",
            "LR: /content/drive/MyDrive/Colab Notebooks/dataset/train/LR/182053_aug6.png\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gyjHS3EbSSzx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}